2020-12-17 01:41:13.450 INFO:	gpus = [0]
2020-12-17 01:41:13.531 INFO:	gpu device = 0
2020-12-17 01:41:13.531 INFO:	args = Namespace(arch_learning_rate=0.0003, arch_search_method='GDAS', arch_weight_decay=0.001, batch_size=128, cutout=False, cutout_length=16, data='../data', drop_path_prob=0.3, epochs=300, gpu='0', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, model_path='saved_models', momentum=0.9, optimization='MiLeNAS', report_freq=50, save='search-EXP-20201217-014112', seed=2, tau_max=10.0, tau_min=1.0, train_portion=0.5, unrolled=True, weight_decay=0.0003)
2020-12-17 01:41:15.409 INFO:	param size = 1.930842MB
Files already downloaded and verified
/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:508: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2020-12-17 01:41:16.068 INFO:	epoch 0 lr 2.500000e-02
2020-12-17 01:41:16.069 INFO:	genotype = Genotype(normal=[('dil_conv_5x5', 1, 0.12510982155799866), ('sep_conv_3x3', 0, 0.12510918080806732), ('dil_conv_3x3', 2, 0.12516863644123077), ('dil_conv_5x5', 1, 0.12513791024684906), ('avg_pool_3x3', 1, 0.12522174417972565), ('dil_conv_5x5', 2, 0.12511184811592102), ('dil_conv_3x3', 0, 0.12528343498706818), ('max_pool_3x3', 3, 0.12528221309185028)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1, 0.12522292137145996), ('sep_conv_5x5', 0, 0.12512429058551788), ('dil_conv_5x5', 0, 0.1254260390996933), ('sep_conv_3x3', 1, 0.12516769766807556), ('max_pool_3x3', 0, 0.1251889169216156), ('avg_pool_3x3', 2, 0.1251487284898758), ('sep_conv_3x3', 4, 0.12518329918384552), ('sep_conv_3x3', 0, 0.12515242397785187)], reduce_concat=range(2, 6))
tensor([[0.1250, 0.1247, 0.1251, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1251],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1248, 0.1251],
        [0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251, 0.1252, 0.1251],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1249, 0.1252, 0.1251, 0.1250, 0.1250, 0.1250, 0.1249],
        [0.1250, 0.1248, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249],
        [0.1249, 0.1249, 0.1249, 0.1250, 0.1249, 0.1250, 0.1253, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1252, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249],
        [0.1249, 0.1253, 0.1250, 0.1248, 0.1248, 0.1251, 0.1251, 0.1250],
        [0.1249, 0.1251, 0.1251, 0.1252, 0.1250, 0.1248, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1249, 0.1250],
        [0.1249, 0.1248, 0.1252, 0.1247, 0.1251, 0.1249, 0.1252, 0.1251],
        [0.1249, 0.1249, 0.1251, 0.1250, 0.1248, 0.1250, 0.1249, 0.1254],
        [0.1251, 0.1250, 0.1250, 0.1250, 0.1252, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1251, 0.1252, 0.1251, 0.1247, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1251, 0.1250, 0.1247, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1248],
        [0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251, 0.1251],
        [0.1252, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1249, 0.1251, 0.1251, 0.1246, 0.1251, 0.1251, 0.1251],
        [0.1250, 0.1247, 0.1250, 0.1251, 0.1252, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
2020-12-17 01:41:17.471 INFO:	train 000 2.332813e+00 11.718750 48.437500
Traceback (most recent call last):
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2020-12-17 01:41:53.008 INFO:	train 050 2.416931e+00 10.968137 54.136029
Traceback (most recent call last):
  File "./search_algorithm/train_gdas.py", line 281, in <module>
    main()
  File "./search_algorithm/train_gdas.py", line 177, in main
    train_acc, train_obj = train(epoch, train_queue, valid_queue, model, architect, criterion, optimizer, lr)
  File "./search_algorithm/train_gdas.py", line 232, in train
    logits = model(input)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 127, in forward
    s0, s1 = s1, cell(s0, s1, weights)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 61, in forward
    s = sum(self._ops[offset + j](h, weights[offset + j]) for j, h in enumerate(states))
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 61, in <genexpr>
    s = sum(self._ops[offset + j](h, weights[offset + j]) for j, h in enumerate(states))
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 24, in forward
    if abs(weight) > 1e-10:
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/tensor.py", line 27, in wrapped
    return f(*args, **kwargs)
KeyboardInterrupt
