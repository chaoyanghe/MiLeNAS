2020-12-17 01:25:54.880 INFO:	gpus = [0]
2020-12-17 01:25:54.949 INFO:	gpu device = 0
2020-12-17 01:25:54.949 INFO:	args = Namespace(arch_learning_rate=0.0003, arch_search_method='GDAS', arch_weight_decay=0.001, batch_size=128, cutout=False, cutout_length=16, data='../data', drop_path_prob=0.3, epochs=250, gpu='0', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, model_path='saved_models', momentum=0.9, optimization='AOS', report_freq=50, save='search-EXP-20201217-012553', seed=2, tau_max=10.0, tau_min=1.0, train_portion=0.5, unrolled=True, weight_decay=0.0003)
2020-12-17 01:25:56.740 INFO:	param size = 1.930842MB
Files already downloaded and verified
/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
2020-12-17 01:25:57.387 INFO:	epoch 0 lr 2.499811e-02
/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:508: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
2020-12-17 01:25:57.389 INFO:	genotype = Genotype(normal=[('dil_conv_5x5', 1, 0.12510982155799866), ('sep_conv_3x3', 0, 0.12510918080806732), ('dil_conv_3x3', 2, 0.12516863644123077), ('dil_conv_5x5', 1, 0.12513791024684906), ('avg_pool_3x3', 1, 0.12522174417972565), ('dil_conv_5x5', 2, 0.12511184811592102), ('dil_conv_3x3', 0, 0.12528343498706818), ('max_pool_3x3', 3, 0.12528221309185028)], normal_concat=range(2, 6), reduce=[('avg_pool_3x3', 1, 0.12522292137145996), ('sep_conv_5x5', 0, 0.12512429058551788), ('dil_conv_5x5', 0, 0.1254260390996933), ('sep_conv_3x3', 1, 0.12516769766807556), ('max_pool_3x3', 0, 0.1251889169216156), ('avg_pool_3x3', 2, 0.1251487284898758), ('sep_conv_3x3', 4, 0.12518329918384552), ('sep_conv_3x3', 0, 0.12515242397785187)], reduce_concat=range(2, 6))
tensor([[0.1250, 0.1247, 0.1251, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1251, 0.1251],
        [0.1251, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1248, 0.1251],
        [0.1250, 0.1250, 0.1251, 0.1249, 0.1249, 0.1250, 0.1250, 0.1251],
        [0.1248, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251, 0.1252, 0.1251],
        [0.1249, 0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1250, 0.1250],
        [0.1249, 0.1249, 0.1252, 0.1251, 0.1250, 0.1250, 0.1250, 0.1249],
        [0.1250, 0.1248, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249],
        [0.1249, 0.1249, 0.1249, 0.1250, 0.1249, 0.1250, 0.1253, 0.1251],
        [0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249, 0.1251],
        [0.1250, 0.1250, 0.1252, 0.1251, 0.1249, 0.1249, 0.1250, 0.1249],
        [0.1249, 0.1253, 0.1250, 0.1248, 0.1248, 0.1251, 0.1251, 0.1250],
        [0.1249, 0.1251, 0.1251, 0.1252, 0.1250, 0.1248, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251, 0.1249, 0.1250],
        [0.1249, 0.1248, 0.1252, 0.1247, 0.1251, 0.1249, 0.1252, 0.1251],
        [0.1249, 0.1249, 0.1251, 0.1250, 0.1248, 0.1250, 0.1249, 0.1254],
        [0.1251, 0.1250, 0.1250, 0.1250, 0.1252, 0.1250, 0.1249, 0.1250],
        [0.1251, 0.1249, 0.1250, 0.1250, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1251, 0.1252, 0.1251, 0.1247, 0.1252, 0.1249, 0.1249, 0.1250],
        [0.1251, 0.1251, 0.1251, 0.1250, 0.1247, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1249, 0.1251, 0.1250, 0.1250, 0.1248, 0.1251, 0.1248],
        [0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250],
        [0.1248, 0.1249, 0.1250, 0.1249, 0.1252, 0.1250, 0.1251, 0.1251],
        [0.1252, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1249, 0.1251, 0.1251, 0.1246, 0.1251, 0.1251, 0.1251],
        [0.1250, 0.1247, 0.1250, 0.1251, 0.1252, 0.1250, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
2020-12-17 01:25:58.720 INFO:	train 000 2.411777e+00 8.593750 49.218750
2020-12-17 01:26:28.455 INFO:	train 050 2.426603e+00 11.902574 55.591299
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fed9a188f70>
Traceback (most recent call last):
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1203, in __del__
    self._shutdown_workers()
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1177, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt: 
Traceback (most recent call last):
  File "./search_algorithm/train_gdas.py", line 280, in <module>
    if __name__ == '__main__':
  File "./search_algorithm/train_gdas.py", line 178, in main
    logging.info('train_acc %f', train_acc)
  File "./search_algorithm/train_gdas.py", line 231, in train
    optimizer.zero_grad()
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 127, in forward
    s0, s1 = s1, cell(s0, s1, weights)
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 61, in forward
    s = sum(self._ops[offset + j](h, weights[offset + j]) for j, h in enumerate(states))
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 61, in <genexpr>
    s = sum(self._ops[offset + j](h, weights[offset + j]) for j, h in enumerate(states))
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/chaoyanghe/sourcecode/MiLeNAS/search_space/model_search_gumbel_softmax.py", line 23, in forward
    for j, weight in enumerate(weights):
  File "/home/chaoyanghe/miniconda/envs/milenas/lib/python3.8/site-packages/torch/tensor.py", line 594, in __iter__
    return iter(self.unbind(0))
KeyboardInterrupt
